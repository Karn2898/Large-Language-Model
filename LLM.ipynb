{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I am going to build a Large Language model and yeah ..that's it"
      ],
      "metadata": {
        "id": "8Q9HSdrLJ-zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.EDA\n"
      ],
      "metadata": {
        "id": "BIyi9AozKHPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akS-sRrQJuv3",
        "outputId": "7dc9cad0-f0e3-4fb7-d60b-516952fa40aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.9.0+cu126\n",
            "tiktoken version: 0.12.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(\"the-verdict.txt\"):\n",
        "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "           \"the-verdict.txt\")\n",
        "    file_path = \"the-verdict.txt\"\n",
        "    urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "JXyov0osKqm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIb2Qi8yKvlD",
        "outputId": "69c182c2-b107-4481-d50b-93215490377c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextdatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "HsaSPUmAqIw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        " def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n"
      ],
      "metadata": {
        "id": "2mNyR9BTq5nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size, max_length, stride,\n",
        "                         shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    dataset = TextdatasetV1atasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n"
      ],
      "metadata": {
        "id": "cTERKssWq8zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "context_length = 1024\n",
        "\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size, max_length, stride,\n",
        "                         shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Corrected typo here\n",
        "    dataset = TextdatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "batch_size = 8\n",
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text,\n",
        "    batch_size=batch_size,\n",
        "    max_length=max_length,\n",
        "    stride=max_length\n",
        ")"
      ],
      "metadata": {
        "id": "YAi3TI81rdKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for batch in dataloader:\n",
        "  x,y = batch\n",
        "\n",
        "  token_embeddingd=token_embedding_layer(x)\n",
        "  pos_embeddings=pos_embedding_layer(torch.arange(max_length))\n",
        "\n",
        "  input_embeddings=token_embeddingd+pos_embeddings\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "C499CIy0rf_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktu_oXIhwiFM",
        "outputId": "c95708cd-52ef-40e6-b69b-b3849fecf338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Attention Mechanisms"
      ],
      "metadata": {
        "id": "IwrJj5wIxtvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version"
      ],
      "metadata": {
        "id": "Yyyt2b-VxwSg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "inputs=torch.tensor( [[0.43, 0.15, 0.89], # Your     (x^1)\n",
        "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
        "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
        "   [0.22, 0.58, 0.33], # with     (x^4)\n",
        "   [0.77, 0.25, 0.10], # one      (x^5)\n",
        "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "Xm3Bd1rGSCEV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=inputs[1]\n",
        "attn_scores_2=torch.empty(inputs.shape[0])\n",
        "for i , x_1 in enumerate(inputs):\n",
        "  attn_scores_2[i]=torch.dot(x_1 , query)\n",
        "\n",
        "  print(attn_scores_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W92-7AVXSWLI",
        "outputId": "a8fd3a3c-3ed9-4b84-8008-0f4a5d089f18"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.5440e-01, 4.3536e-41, 2.8320e-24, 0.0000e+00, 0.0000e+00, 0.0000e+00])\n",
            "tensor([9.5440e-01, 1.4950e+00, 2.8320e-24, 0.0000e+00, 0.0000e+00, 0.0000e+00])\n",
            "tensor([0.9544, 1.4950, 1.4754, 0.0000, 0.0000, 0.0000])\n",
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.0000, 0.0000])\n",
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 0.0000])\n",
            "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res =0\n",
        "\n",
        "for idx , element in enumerate (inputs[0]):\n",
        "    res+=inputs[0][idx ]*query[idx]\n",
        "\n",
        "    print(res)\n",
        "    print(torch.dot(inputs[0],query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YoulooESyfN",
        "outputId": "9a5c7c5d-8ede-4c55-fd4d-f2468ed41926"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2365)\n",
            "tensor(0.9544)\n",
            "tensor(0.3670)\n",
            "tensor(0.9544)\n",
            "tensor(0.9544)\n",
            "tensor(0.9544)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2_tmp=attn_scores_2/attn_scores_2.sum()\n",
        "print(\"Attetion weights:\", attn_weights_2_tmp)\n",
        "print(\"sum:\",attn_weights_2_tmp.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv_uCBQjTY4Q",
        "outputId": "50e4d888-b2d1-4e68-991a-75cfbb541c23"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attetion weights: tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
            "sum: tensor(1.0000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_naive(x):\n",
        "  return torch.exp(x)/torch.exp(x).sum(dim=0)\n",
        "\n",
        "  attn_weights_2_naive=softmax_naive(attn_scores_2)\n",
        "  print(\"attention weights:\",attn_weights_2_naive)\n",
        "  print(\"sum:\", attn_weights_2_naive.sum())"
      ],
      "metadata": {
        "id": "hg0YxDFUUFoH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights_2=torch.softmax(attn_scores_2,dim=0)\n",
        "\n",
        "print(\"Attention weights:\",attn_weights_2)\n",
        "print(\"sum:\",attn_weights_2.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52_Va6okUZOU",
        "outputId": "4377189a-dd8b-415a-bc4b-56cb9027843c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
            "sum: tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compute theb context vector\n",
        "query=inputs[1]\n",
        "context_vec_2=torch.zeros(query.shape)\n",
        "for i ,x_i in enumerate(inputs):\n",
        "  context_vec_2+=attn_weights_2[i]*x_i\n",
        "\n",
        "  print(context_vec_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjLMMA1yU3jO",
        "outputId": "daf94c71-1607-4c34-abca-17480608f531"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0596, 0.0208, 0.1233])\n",
            "tensor([0.1904, 0.2277, 0.2803])\n",
            "tensor([0.3234, 0.4260, 0.4296])\n",
            "tensor([0.3507, 0.4979, 0.4705])\n",
            "tensor([0.4340, 0.5250, 0.4813])\n",
            "tensor([0.4419, 0.6515, 0.5683])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores=torch.empty(6,6)\n",
        "for i , x_i in enumerate (inputs):\n",
        "  for j,x_j in enumerate(inputs):\n",
        "    attn_scores[i,j]=torch.dot(x_i,x_i)\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDOj14AgVquc",
        "outputId": "73ae6942-15c3-4025-96b0-b500060c06b9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9995, 0.9995, 0.9995, 0.9995, 0.9995],\n",
            "        [1.4950, 1.4950, 1.4950, 1.4950, 1.4950, 1.4950],\n",
            "        [1.4570, 1.4570, 1.4570, 1.4570, 1.4570, 1.4570],\n",
            "        [0.4937, 0.4937, 0.4937, 0.4937, 0.4937, 0.4937],\n",
            "        [0.6654, 0.6654, 0.6654, 0.6654, 0.6654, 0.6654],\n",
            "        [0.9450, 0.9450, 0.9450, 0.9450, 0.9450, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_scores=inputs @ inputs.T\n",
        "print(attn_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUhwCfnVWZTH",
        "outputId": "01dee557-3b1f-40af-b46a-ba44fb7aeec5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
            "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
            "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
            "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
            "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
            "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attn_weights=torch.softmax(attn_scores,dim=1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of6Vugx8WtyE",
        "outputId": "c0abe288-674d-48e6-de20-06b2b36e9617"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_context_vectors=attn_weights @ inputs\n",
        "print(all_context_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHPowRkcW-Rm",
        "outputId": "f722fc33-39c0-420f-e4c5-7cb0c9203e99"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_2=inputs[1]\n",
        "d_in=inputs.shape[1]\n",
        "d_out=2\n",
        "\n",
        "torch.manual_seed(123)\n",
        "w_query = torch.randn(d_in, d_out)\n",
        "w_key = torch.randn(d_in, d_out)\n",
        "w_value = torch.randn(d_in, d_out)\n",
        "\n",
        "query = inputs @ w_query\n",
        "keys = inputs @ w_key\n",
        "values = inputs @ w_value\n",
        "\n",
        "attn_scores_2=query[1] @ keys.T\n",
        "print(attn_scores_2)\n",
        "\n",
        "d_k=keys.shape[1]\n",
        "attn_weights_2=torch.softmax(attn_scores_2/d_k**0.5,dim=-1)\n",
        "print(attn_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVuhInAJXV4t",
        "outputId": "42287a08-490c-472a-c3fb-7b902a9c2de6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.2172,  0.1376,  0.1730, -0.0491,  0.7616, -0.3809])\n",
            "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
            "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
            "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
            "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
            "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
            "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
          ]
        }
      ]
    }
  ]
}