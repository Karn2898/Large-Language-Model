{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "I am going to build a Large Language model and yeah ..that's it"
      ],
      "metadata": {
        "id": "8Q9HSdrLJ-zH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.EDA\n"
      ],
      "metadata": {
        "id": "BIyi9AozKHPM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akS-sRrQJuv3",
        "outputId": "16656a56-7cdd-46ee-e2a5-c74180325b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.9.0+cpu\n",
            "tiktoken version: 0.12.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(\"the-verdict.txt\"):\n",
        "    url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
        "           \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
        "           \"the-verdict.txt\")\n",
        "    file_path = \"the-verdict.txt\"\n",
        "    urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "id": "JXyov0osKqm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIb2Qi8yKvlD",
        "outputId": "523478ee-4920-4927-bd48-2fe8981064b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextdatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "HsaSPUmAqIw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        " def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n"
      ],
      "metadata": {
        "id": "2mNyR9BTq5nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_dataloader_v1(txt, batch_size, max_length, stride,\n",
        "                         shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    dataset = TextdatasetV1atasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n"
      ],
      "metadata": {
        "id": "cTERKssWq8zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "vocab_size = 50257\n",
        "output_dim = 256\n",
        "context_length = 1024\n",
        "\n",
        "\n",
        "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
        "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size, max_length, stride,\n",
        "                         shuffle=True, drop_last=True, num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Corrected typo here\n",
        "    dataset = TextdatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "batch_size = 8\n",
        "max_length = 4\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text,\n",
        "    batch_size=batch_size,\n",
        "    max_length=max_length,\n",
        "    stride=max_length\n",
        ")"
      ],
      "metadata": {
        "id": "YAi3TI81rdKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " for batch in dataloader:\n",
        "  x,y = batch\n",
        "\n",
        "  token_embeddingd=token_embedding_layer(x)\n",
        "  pos_embeddings=pos_embedding_layer(torch.arange(max_length))\n",
        "\n",
        "  input_embeddings=token_embeddingd+pos_embeddings\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "C499CIy0rf_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktu_oXIhwiFM",
        "outputId": "4c64e4c2-3dc7-47aa-f568-515890c8a4a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Attention Mechanisms"
      ],
      "metadata": {
        "id": "IwrJj5wIxtvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "multi head attention"
      ],
      "metadata": {
        "id": "A7pTljgU4zEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.d_out = d_out\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
        "\n",
        "  def forward(self, x):\n",
        "    b, n_tokens, d_in = x.shape\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    attn_scores = queries @ keys.transpose(1, 2)\n",
        "    attn_scores.masked_fill_(self.mask[:n_tokens, :n_tokens], -torch.inf)\n",
        "    attn_weights = torch.softmax(attn_scores / (keys.shape[-1]**0.5), dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vec = attn_weights @ values\n",
        "    return context_vec\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_out = d_out\n",
        "    self.heads = nn.ModuleList(\n",
        "        [CausalSelfAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
        "         for _ in range(num_heads)]\n",
        "    )\n",
        "    self.out_proj = nn.Linear(num_heads * d_out, d_out)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    context_vecs = torch.cat([head(x) for head in self.heads], dim=-1)\n",
        "\n",
        "    return self.out_proj(context_vecs)"
      ],
      "metadata": {
        "id": "-C6JBj3H5WMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "d_in = output_dim\n",
        "d_out = output_dim\n",
        "num_heads = 8\n",
        "context_length = max_length\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads)\n",
        "\n",
        "batch = input_embeddings\n",
        "context_vecs = mha(batch)\n",
        "\n",
        "print(\"context_vecs.shape:\", context_vecs.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GVuZwHy4vkh",
        "outputId": "f672b56d-deed-4570-ca5a-820dadb190f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "context_vecs.shape: torch.Size([8, 4, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing the GPT text to generate words"
      ],
      "metadata": {
        "id": "ku9TewqRGg-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self,emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps=1e-5\n",
        "    self.scale=nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self,x):\n",
        "    mean=x.mean(dim=-1,keepdim=True)\n",
        "    var=x.var(dim=-1,keepdim=True,unbiased=False)\n",
        "    norm_x=(x-mean)/torch.sqrt(var+self.eps)\n",
        "    return self.scale*norm_x+self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return 0.5 * x * (1+torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi))*\n",
        "        (x+0.044715 * torch.pow(x,3))\n",
        "    ))"
      ],
      "metadata": {
        "id": "ZtVGTWnf8iyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.layers=nn.Sequential(\n",
        "        nn.Linear(cfg[\"emb_dim\"],4*cfg[\"emb_dim\"]),\n",
        "        GELU(),\n",
        "        nn.Linear(4*cfg[\"emb_dim\"],cfg[\"emb_dim\"])\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self,cfg):\n",
        "    super().__init__()\n",
        "    self.att=MultiHeadAttention(\n",
        "        d_in=cfg[\"emb_dim\"],\n",
        "        d_out=cfg[\"emb_dim\"],\n",
        "        context_length=cfg[\"context_length\"],\n",
        "        num_heads=cfg[\"n_heads\"],\n",
        "        dropout=cfg[\"drop_rate\"],\n",
        "        qkv_bias=cfg[\"qkv_bias\"]\n",
        "    )\n",
        "\n",
        "    self.ff=FeedForward(cfg)\n",
        "    self.norm1=LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2=LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.drop_shortcut=nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "    x = self.att(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.ff(x)\n",
        "    x = self.drop_shortcut(x)\n",
        "    x = x + shortcut\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "nfioRdz4Icvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "        *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])]\n",
        "    )\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "  def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x)\n",
        "    x = self.trf_blocks(x)\n",
        "    x = self.final_norm(x)\n",
        "    logits = self.out_head(x)\n",
        "    return logits\n",
        "\n",
        "  def generate_text_Simple(self, idx, max_new_tokens, context_length):\n",
        "    for _ in range(max_new_tokens):\n",
        "      idx_cond = idx[:, -context_length:]\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logits = self(idx_cond)\n",
        "\n",
        "\n",
        "      logits = logits[:, -1, :]\n",
        "      idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "      idx = torch.cat((idx, idx_next), dim=-1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "uRIK4TT2K60x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "  def __init__(self,emb_dim):\n",
        "    super().__init__()\n",
        "    self.eps=1e-5\n",
        "    self.scale=nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift=nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "  def forward(self,x):\n",
        "    mean=x.mean(dim=-1,keepdim=True)\n",
        "    var=x.var(dim=-1,keepdim=True,unbiased=False)\n",
        "    norm_x=(x-mean)/torch.sqrt(var+self.eps)\n",
        "    return self.scale*norm_x+self.shift\n",
        "\n",
        "class GELU(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self,x):\n",
        "    return 0.5 * x * (1+torch.tanh(\n",
        "        torch.sqrt(torch.tensor(2.0/torch.pi))*\n",
        "        (x+0.044715 * torch.pow(x,3))\n",
        "    ))\n",
        "\n",
        "def main():\n",
        "  GPT_CONFIG_124M={\n",
        "    \"vocab_size\": 50257,\n",
        "        \"context_length\": 1024,\n",
        "        \"emb_dim\": 768,\n",
        "        \"n_heads\": 12,\n",
        "        \"n_layers\": 12,\n",
        "        \"drop_rate\": 0.1,\n",
        "        \"qkv_bias\": False\n",
        "  }\n",
        "\n",
        "  torch.manual_seed(123)\n",
        "  model=GPTModel(GPT_CONFIG_124M)\n",
        "  model.eval()\n",
        "\n",
        "  start_context=\"Hello, I am\"\n",
        "\n",
        "  tokenizer=tiktoken.get_encoding(\"gpt2\")\n",
        "  encoded=tokenizer.encode(start_context)\n",
        "  encoded_tensor=torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "  print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
        "  print(\"\\nInput text:\", start_context)\n",
        "  print(\"Encoded input text:\", encoded)\n",
        "  print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
        "\n",
        "  out=model.generate_text_Simple(\n",
        "      idx=encoded_tensor,\n",
        "      max_new_tokens=10,\n",
        "      context_length=GPT_CONFIG_124M[\"context_length\"]\n",
        "  )\n",
        "\n",
        "  decoded_text=tokenizer.decode(out.squeeze(0).tolist())\n",
        "  print(f\"\\n\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
        "  print(\"\\nOutput:\", out)\n",
        "  print(\"Output length:\", len(out[0]))\n",
        "  print(\"Output text:\", decoded_text)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfvPRvB2NwPJ",
        "outputId": "6daaa82d-3109-4385-8ca2-58bf941b4057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "                      IN\n",
            "==================================================\n",
            "\n",
            "Input text: Hello, I am\n",
            "Encoded input text: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n",
            "\n",
            "\n",
            "==================================================\n",
            "                      OUT\n",
            "==================================================\n",
            "\n",
            "Output: tensor([[15496,    11,   314,   716,  1686, 17362, 37021,  6805, 33311, 40953,\n",
            "         29515, 46248,  6723,  5409]])\n",
            "Output length: 14\n",
            "Output text: Hello, I amaps BaseballEdge components Keeping loosenetsksomeone SS decide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import requests\n",
        "import torch\n",
        "import tiktoken\n"
      ],
      "metadata": {
        "id": "A_XjP5Xzpf2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  llms_from_scratch.ch04 import GPTModel"
      ],
      "metadata": {
        "id": "onhBrWXrfj5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 256,\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": False\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "7cn_No1MmvDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text)\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "       token_ids = generate_text_simple(\n",
        "    model=model,  # Pass model as an argument\n",
        "    idx=encoded,\n",
        "    max_new_tokens=50,\n",
        "    context_size=context_size\n",
        ")\n",
        "decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neWu0pZPnpHz",
        "outputId": "63755d7f-e784-4d3f-e1ee-af91654bd5fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(1024, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen = 0\n",
        "    global_step = -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ],
      "metadata": {
        "id": "vTAYmV_Vn1CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.show() # Ensure plt.show() is called\n",
        "\n",
        "\n",
        "def main(gpt_config, settings):\n",
        "\n",
        "    torch.manual_seed(123)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "    file_path = \"the-verdict.txt\"\n",
        "    url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        response = requests.get(url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        text_data = response.text\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    # Model initialization\n",
        "    model = GPTModel(gpt_config)\n",
        "    model.to(device)\n",
        "\n",
        "    # Optimizer setup\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(), lr=settings[\"learning_rate\"], weight_decay=settings[\"weight_decay\"]\n",
        "    )\n",
        "\n",
        "    # Dataloader creation\n",
        "    train_ratio = 0.90\n",
        "    split_idx = int(train_ratio * len(text_data))\n",
        "\n",
        "    train_loader = create_dataloader_v1(\n",
        "        text_data[:split_idx],\n",
        "        batch_size=settings[\"batch_size\"],\n",
        "        max_length=gpt_config[\"context_length\"],\n",
        "        stride=gpt_config[\"context_length\"],\n",
        "        drop_last=True,\n",
        "        shuffle=True,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    val_loader = create_dataloader_v1(\n",
        "        text_data[split_idx:],\n",
        "        batch_size=settings[\"batch_size\"],\n",
        "        max_length=gpt_config[\"context_length\"],\n",
        "        stride=gpt_config[\"context_length\"],\n",
        "        drop_last=False,\n",
        "        shuffle=False,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Training loop call\n",
        "    train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "        model, train_loader, val_loader, optimizer, device,\n",
        "        num_epochs=settings[\"num_epochs\"], eval_freq=5, eval_iter=1,\n",
        "        start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        "    )\n",
        "\n",
        "    return train_losses, val_losses, tokens_seen, model"
      ],
      "metadata": {
        "id": "ANi5lBqXop-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(gpt_config)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "model.parameters(), lr=settings[\"learning_rate\"], weight_decay=settings[\"weight_decay\"]\n",
        "    )\n",
        "\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "        text_data[:split_idx],\n",
        "        batch_size=settings[\"batch_size\"],\n",
        "        max_length=gpt_config[\"context_length\"],\n",
        "        stride=gpt_config[\"context_length\"],\n",
        "        drop_last=True,\n",
        "        shuffle=True,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "        text_data[split_idx:],\n",
        "        batch_size=settings[\"batch_size\"],\n",
        "        max_length=gpt_config[\"context_length\"],\n",
        "        stride=gpt_config[\"context_length\"],\n",
        "        drop_last=False,\n",
        "        shuffle=False,\n",
        "        num_workers=0\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "FcLDWAxLpCFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    GPT_CONFIG_124M = {\n",
        "        \"vocab_size\": 50257,\n",
        "        \"context_length\": 256,\n",
        "        \"emb_dim\": 768,\n",
        "        \"n_heads\": 12,\n",
        "        \"n_layers\": 12,\n",
        "        \"drop_rate\": 0.1,\n",
        "        \"qkv_bias\": False\n",
        "    }\n",
        "\n",
        "    OTHER_SETTINGS = {\n",
        "        \"learning_rate\": 5e-4,\n",
        "        \"num_epochs\": 10,\n",
        "        \"batch_size\": 2,\n",
        "        \"weight_decay\": 0.1\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    train_losses, val_losses, tokens_seen, model = main(GPT_CONFIG_124M, OTHER_SETTINGS)\n",
        "\n",
        "\n",
        "\n",
        "    # Plot results\n",
        "    epochs_tensor = torch.linspace(0, OTHER_SETTINGS[\"num_epochs\"], len(train_losses))\n",
        "    plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)\n",
        "    plt.savefig(\"loss.pdf\")\n",
        "\n",
        "    # Save and load model\n",
        "    torch.save(model.state_dict(), \"model.pth\")\n",
        "    model = GPTModel(GPT_CONFIG_124M)\n",
        "    model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "YbPqJQq4pQNA",
        "outputId": "4cf11351-02a0-49dd-85ed-fb77a4bf3607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 9.812, Val loss 9.846\n",
            "Ep 1 (Step 000005): Train loss 7.588, Val loss 8.044\n",
            "Ep 2 (Step 000010): Train loss 6.582, Val loss 6.800\n",
            "Ep 2 (Step 000015): Train loss 5.920, Val loss 6.592\n",
            "Ep 3 (Step 000020): Train loss 15.767, Val loss 16.154\n",
            "Ep 3 (Step 000025): Train loss 5.494, Val loss 6.384\n",
            "Ep 4 (Step 000030): Train loss 4.373, Val loss 6.328\n",
            "Ep 4 (Step 000035): Train loss 2.824, Val loss 6.258\n",
            "Ep 5 (Step 000040): Train loss 3.969, Val loss 6.221\n",
            "Ep 6 (Step 000045): Train loss 2.638, Val loss 6.221\n",
            "Ep 6 (Step 000050): Train loss 3.156, Val loss 6.194\n",
            "Ep 7 (Step 000055): Train loss 2.676, Val loss 6.162\n",
            "Ep 7 (Step 000060): Train loss 1.728, Val loss 6.274\n",
            "Ep 8 (Step 000065): Train loss 0.933, Val loss 6.259\n",
            "Ep 8 (Step 000070): Train loss 1.371, Val loss 6.272\n",
            "Ep 9 (Step 000075): Train loss 0.762, Val loss 6.329\n",
            "Ep 9 (Step 000080): Train loss 0.563, Val loss 6.462\n",
            "Ep 10 (Step 000085): Train loss 0.358, Val loss 6.542\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finetuning"
      ],
      "metadata": {
        "id": "8nqggWwU9HOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "IHyuSzBY9NuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/rasbt/LLMs-from-scratch.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbOEof6D_tMl",
        "outputId": "4e9add1e-5f4e-4840-86c1-df1b5461c357"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/rasbt/LLMs-from-scratch.git\n",
            "  Cloning https://github.com/rasbt/LLMs-from-scratch.git to /tmp/pip-req-build-thh5lxj_\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rasbt/LLMs-from-scratch.git /tmp/pip-req-build-thh5lxj_\n",
            "  Resolved https://github.com/rasbt/LLMs-from-scratch.git to commit 695ecb61cef496b661d9b799d6965c07370aa8d6\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (2.19.0)\n",
            "Collecting jupyterlab>=4.0 (from llms-from-scratch==1.0.18)\n",
            "  Downloading jupyterlab-4.5.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (0.12.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (2.2.2)\n",
            "Collecting pip>=25.0.1 (from llms-from-scratch==1.0.18)\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: pytest>=8.3.5 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (8.4.2)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.28.1)\n",
            "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (5.9.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.0)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (6.5.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.1->llms-from-scratch==1.0.18) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.1->llms-from-scratch==1.0.18) (2025.3)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch==1.0.18) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch==1.0.18) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch==1.0.18) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (2.32.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.5.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->llms-from-scratch==1.0.18) (2025.11.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.45.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (26.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.0.3)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.23.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.5.1)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.25.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.1.4)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.30.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.4)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.21.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (4.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.8.5)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.10.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.2.14)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.23)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.4.0)\n",
            "Downloading jupyterlab-4.5.1-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llms-from-scratch\n",
            "  Building wheel for llms-from-scratch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llms-from-scratch: filename=llms_from_scratch-1.0.18-py3-none-any.whl size=85993 sha256=c6012ec4f0e220a7ee50fd3e4264c86ca96e24ec4660755e1de67794bcb78111\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rkuc2n2m/wheels/69/77/60/5aeaba865ec259057fd38b9ea4e7e81eaaf0c0b31fb312eb68\n",
            "Successfully built llms-from-scratch\n",
            "Installing collected packages: pip, json5, jedi, async-lru, jupyterlab-server, jupyter-lsp, jupyterlab, llms-from-scratch\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed async-lru-2.0.5 jedi-0.19.2 json5-0.12.1 jupyter-lsp-2.3.0 jupyterlab-4.5.1 jupyterlab-server-2.28.0 llms-from-scratch-1.0.18 pip-25.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import llms_from_scratch\n"
      ],
      "metadata": {
        "id": "EmiZ72AGAuo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import load_weights_into_gpt\n"
      ],
      "metadata": {
        "id": "KbG1xXY0Ayff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Downloading the file\n",
        "    response = requests.get(url, stream=True, timeout=60)\n",
        "    response.raise_for_status()\n",
        "    with open(zip_path, \"wb\") as out_file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            if chunk:\n",
        "                out_file.write(chunk)\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")"
      ],
      "metadata": {
        "id": "BSN6akkCA3Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_balanced_dataset(df):\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "\n",
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df"
      ],
      "metadata": {
        "id": "FV8OpgGPBc8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length == None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length\n",
        "        # Note: A more pythonic version to implement this method\n",
        "        # is the following, which is also used in the next chapter:\n",
        "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)\n",
        "\n",
        "\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples\n"
      ],
      "metadata": {
        "id": "2DxTUWXOB--A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n"
      ],
      "metadata": {
        "id": "JeAUgWTJCLcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()  # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()  # Calculate loss gradients\n",
        "            optimizer.step()  # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0]  # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2bjcpkGKCqNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "nGyibImRCwAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Finetune a GPT model for classification\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--test_mode\",\n",
        "        default=False,\n",
        "        action=\"store_true\",\n",
        "        help=(\"This flag runs the model in test mode for internal testing purposes. \"\n",
        "              \"Otherwise, it runs the model as it is used in the chapter (recommended).\")\n",
        "    )\n",
        "    args = parser.parse_args([]) # Pass an empty list to ignore kernel arguments\n",
        "\n",
        "    url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "    zip_path = \"sms_spam_collection.zip\"\n",
        "    extracted_path = \"sms_spam_collection\"\n",
        "    data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "    try:\n",
        "        download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "    except (requests.exceptions.RequestException, TimeoutError) as e:\n",
        "        print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
        "        url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
        "        download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "\n",
        "    df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "    balanced_df = create_balanced_dataset(df)\n",
        "    balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "\n",
        "    train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "    train_df.to_csv(\"train.csv\", index=None)\n",
        "    validation_df.to_csv(\"validation.csv\", index=None)\n",
        "    test_df.to_csv(\"test.csv\", index=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnZcLelQCySB",
        "outputId": "750e6247-230d-452b-e5b9-a1cfbe684b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloaders\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n"
      ],
      "metadata": {
        "id": "WSZoFlEZC5xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZpR6RZKE_wR",
        "outputId": "2e299208-36d7-4912-dba6-e655c1509aeb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-20 21:45:24--  https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5972 (5.8K) [text/plain]\n",
            "Saving to: â€˜gpt_download.py.1â€™\n",
            "\n",
            "\rgpt_download.py.1     0%[                    ]       0  --.-KB/s               \rgpt_download.py.1   100%[===================>]   5.83K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-20 21:45:24 (65.9 MB/s) - â€˜gpt_download.py.1â€™ saved [5972/5972]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch05/01_main-chapter-code/gpt_download.py\"\n",
        "urllib.request.urlretrieve(url, \"gpt_download.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVdhvz8VFBX5",
        "outputId": "21b23f8f-a3cc-417e-af67-af918c80adcb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('gpt_download.py', <http.client.HTTPMessage at 0x7c3cebb22120>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4JbyP0jFF-P",
        "outputId": "3a390b77-ff30-416f-a82d-bb03fa345080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.11.12)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "\n",
        "\n",
        "settings, params = download_and_load_gpt2(model_size=\"355M\", models_dir=\"gpt2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAjuQKtrFHlS",
        "outputId": "d0cc9884-1449-4683-f072-b080f4525b66"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/355M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/355M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/355M/hparams.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.42G/1.42G [02:08<00:00, 11.0MiB/s]\n",
            "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.4k/10.4k [00:00<00:00, 15.1MiB/s]\n",
            "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 927k/927k [00:00<00:00, 2.62MiB/s]\n",
            "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 1.39MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pretrained model\n",
        "if args.test_mode:\n",
        "        BASE_CONFIG = {\n",
        "            \"vocab_size\": 50257,\n",
        "            \"context_length\": 120,\n",
        "            \"drop_rate\": 0.0,\n",
        "            \"qkv_bias\": False,\n",
        "            \"emb_dim\": 12,\n",
        "            \"n_layers\": 1,\n",
        "            \"n_heads\": 2\n",
        "        }\n",
        "        model = GPTModel(BASE_CONFIG)\n",
        "        model.eval()\n",
        "        device = \"cpu\"\n",
        "\n",
        "    # Code as it is used in the main chapter\n",
        "else:\n",
        "        CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "        INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "        BASE_CONFIG = {\n",
        "            \"vocab_size\": 50257,     # Vocabulary size\n",
        "            \"context_length\": 1024,  # Context length\n",
        "            \"drop_rate\": 0.0,        # Dropout rate\n",
        "            \"qkv_bias\": True         # Query-key-value bias\n",
        "        }\n",
        "\n",
        "        model_configs = {\n",
        "            \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "            \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "            \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "            \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "        }\n",
        "\n",
        "        BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "        assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "            f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "            f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "            f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        "        )\n",
        "\n",
        "        model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "        settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "        model = GPTModel(BASE_CONFIG)\n",
        "        load_weights_into_gpt(model, params)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TV4u0fjDw3H",
        "outputId": "a2f2ef0b-a7c9-491d-bee9-6de52ecc863b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "\n",
        "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
        "    if (major, minor) >= (2, 9):\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP2j7uuBUuVJ",
        "outputId": "0a2f77fd-9304-44af-f53d-ab67539eafbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Training accuracy: 95.00%\n",
            "Validation accuracy: 98.75%\n",
            "Test accuracy: 95.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FG3As7VVAn_",
        "outputId": "b4c89347-c328-4635-e6cd-99e2935e1667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.072\n",
            "Validation loss: 0.081\n",
            "Test loss: 0.354\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmA0w59_UMIh",
        "outputId": "511af35f-0d7c-4965-8a10-1993a9c73e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "Mq6-to5DD4pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finetune modified model\n",
        "start_time = time.time()\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQekREQWFeRW",
        "outputId": "b161ecb5-7205-4eac-90e8-b9722725f837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.153, Val loss 2.392\n",
            "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
            "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
            "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
            "Ep 2 (Step 000150): Train loss 0.561, Val loss 0.489\n",
            "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.397\n",
            "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
            "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
            "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.320\n",
            "Ep 3 (Step 000350): Train loss 0.340, Val loss 0.306\n",
            "Training accuracy: 90.00% | Validation accuracy: 90.00%\n",
            "Ep 4 (Step 000400): Train loss 0.136, Val loss 0.200\n",
            "Ep 4 (Step 000450): Train loss 0.153, Val loss 0.132\n",
            "Ep 4 (Step 000500): Train loss 0.222, Val loss 0.137\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Ep 5 (Step 000550): Train loss 0.207, Val loss 0.143\n",
            "Ep 5 (Step 000600): Train loss 0.083, Val loss 0.074\n",
            "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
            "Training completed in 54.86 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    # loss plot\n",
        "    epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "    examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "    plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)\n",
        "\n",
        "    # accuracy plot\n",
        "    epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "    examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "    plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "_xfQNvjWGF3E",
        "outputId": "cc0c06b5-8ae3-4a76-f0b2-f59ddd34c679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#using the model as a spam classifier"
      ],
      "metadata": {
        "id": "7O2iTe-TWAgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "    assert max_length is not None, (\n",
        "        \"max_length must be specified. If you want to use the full model context, \"\n",
        "        \"pass max_length=model.pos_emb.weight.shape[0].\"\n",
        "    )\n",
        "    assert max_length <= supported_context_length, (\n",
        "        f\"max_length ({max_length}) exceeds model's supported context length ({supported_context_length}).\"\n",
        "    )\n",
        "\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"spam\" if predicted_label == 1 else \"not spam\""
      ],
      "metadata": {
        "id": "GFnwgimNTFSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "id": "aZamTEKCWd-N",
        "outputId": "50ba3e57-0e9e-4e82-b834-0bf07c853802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ],
      "metadata": {
        "id": "AbbZOzYiWgys",
        "outputId": "b9ac3396-b89b-4f45-d334-9379e23f20d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "not spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ],
      "metadata": {
        "id": "8knVLmpuWjCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
        "model.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "id": "X5WyjDICWp0s",
        "outputId": "cefe87a1-e20c-4fe1-e673-5f86188df3d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#finetuning for following instructions"
      ],
      "metadata": {
        "id": "a-lTW32xlr5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\n",
        "    \"numpy\",\n",
        "    \"matplotlib\",\n",
        "    \"tiktoken\",\n",
        "    \"torch\",\n",
        "    \"tqdm\",\n",
        "    \"tensorflow\",\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnAhnxeYl056",
        "outputId": "29d6bb62-157b-479b-c2d5-4c93d3ca3583"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy version: 2.0.2\n",
            "matplotlib version: 3.10.0\n",
            "tiktoken version: 0.12.0\n",
            "torch version: 2.9.0+cu126\n",
            "tqdm version: 4.67.1\n",
            "tensorflow version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "prepearingthe datasett\n"
      ],
      "metadata": {
        "id": "r3gHn_a8pvc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import json\n",
        "import os\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "\n",
        "    try:\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "        print(f\"Downloaded and saved file to {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading or writing file: {e}\")\n",
        "\n",
        "        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:\n",
        "            raise IOError(f\"Could not download file and {file_path} is empty or does not exist locally.\") from e\n",
        "        else:\n",
        "            print(f\"Proceeding with existing (possibly old) file at {file_path} due to download error.\")\n",
        "\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"/content/instruction_data\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jlycVxJohCZ",
        "outputId": "76205c63-3160-436f-b202-ec8249372ade"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded and saved file to /content/instruction_data\n",
            "Number of entries: 1100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text\n",
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb9VAAQ8pMp2",
        "outputId": "f28c931b-a4ca-4d9e-9fa1-9a17bdfebc39"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ],
      "metadata": {
        "id": "2SP6KjjHqPRw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data batches\n"
      ],
      "metadata": {
        "id": "EFvMuA7fqlL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "-piRjk2Hqmo2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jv5Y8DQoqs3t",
        "outputId": "5bb4f79d-bf16-4bff-8d5f-a90dd8618019"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "\n",
        "        new_item += [pad_token_id]\n",
        "\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ],
      "metadata": {
        "id": "vd2uwIAvqyt8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLNGdIcsrLMl",
        "outputId": "5996fb9a-5264-4758-a9c7-b9bc0a4057e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "3pZA0cohrLoB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEIuEUJzrQLN",
        "outputId": "daad35bb-da34-4589-a34a-f4973d7fab2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "FR3p4A3ArVNB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataloaders"
      ],
      "metadata": {
        "id": "EHWFztDqsJvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    # Use PyTorch 2.9 or newer for stable mps results\n",
        "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
        "    if (major, minor) >= (2, 9):\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTGyyCBAsK3t",
        "outputId": "b6f85c0c-53a2-4ef3-c95a-7cc9b06bdec1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ],
      "metadata": {
        "id": "7weS0ziDsm2y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    # Use PyTorch 2.9 or newer for stable mps results\n",
        "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
        "    if (major, minor) >= (2, 9):\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTKl3mXrsRbA",
        "outputId": "1ebc6eaa-1cd5-4530-813f-f7d014457e21"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S3t54qHst46",
        "outputId": "dbdacca5-fdae-4e78-f2d1-9f39faf2f076"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(targets[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnRL3XuaszK6",
        "outputId": "92cd2430-ea27-49af-e788-152d9c4840b6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
            "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
            "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
            "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
            "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
            "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading pre trained LLM"
      ],
      "metadata": {
        "id": "MoY0ODTys0xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch04 import GPTModel\n",
        "from llms_from_scratch.ch05 import download_and_load_gpt2, load_weights_into_gpt\n",
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1aGYnnBszmd",
        "outputId": "099d74c5-43aa-4d25-9ddd-d384651f2d67"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77.0/77.0 [00:00<00:00, 164kiB/s]\n",
            "encoder.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.04M/1.04M [00:00<00:00, 3.68MiB/s]\n",
            "hparams.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 91.0/91.0 [00:00<00:00, 180kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.42G/1.42G [01:36<00:00, 14.8MiB/s]\n",
            "model.ckpt.index: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10.4k/10.4k [00:00<00:00, 14.9MiB/s]\n",
            "model.ckpt.meta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 927k/927k [00:00<00:00, 2.90MiB/s]\n",
            "vocab.bpe: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 456k/456k [00:00<00:00, 2.28MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/rasbt/LLMs-from-scratch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aitQtaYjs7G5",
        "outputId": "bac6c8bc-937e-4c2a-a5be-305585ed12bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/rasbt/LLMs-from-scratch.git\n",
            "  Cloning https://github.com/rasbt/LLMs-from-scratch.git to /tmp/pip-req-build-87cg3lk6\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rasbt/LLMs-from-scratch.git /tmp/pip-req-build-87cg3lk6\n",
            "  Resolved https://github.com/rasbt/LLMs-from-scratch.git to commit 695ecb61cef496b661d9b799d6965c07370aa8d6\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (2.19.0)\n",
            "Collecting jupyterlab>=4.0 (from llms-from-scratch==1.0.18)\n",
            "  Downloading jupyterlab-4.5.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (0.12.0)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2.1 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (2.2.2)\n",
            "Collecting pip>=25.0.1 (from llms-from-scratch==1.0.18)\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: pytest>=8.3.5 in /usr/local/lib/python3.12/dist-packages (from llms-from-scratch==1.0.18) (8.4.2)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.28.1)\n",
            "Requirement already satisfied: ipykernel!=6.30.0,>=6.5.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (6.17.1)\n",
            "Requirement already satisfied: jinja2>=3.0.3 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.1.6)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (5.9.1)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading jupyter_lsp-2.3.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.14.0)\n",
            "Collecting jupyterlab-server<3,>=2.28.0 (from jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading jupyterlab_server-2.28.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.2.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.0)\n",
            "Requirement already satisfied: setuptools>=41.1.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (75.2.0)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (6.5.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.12/dist-packages (from jupyterlab>=4.0->llms-from-scratch==1.0.18) (5.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.7.1->llms-from-scratch==1.0.18) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.1->llms-from-scratch==1.0.18) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2.1->llms-from-scratch==1.0.18) (2025.3)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch==1.0.18) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch==1.0.18) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.5->llms-from-scratch==1.0.18) (2.19.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (2.32.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.5.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.5.1->llms-from-scratch==1.0.18) (2025.11.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.45.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.16.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (26.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.0.3->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.0.3)\n",
            "Requirement already satisfied: argon2-cffi>=21.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.1.0)\n",
            "Requirement already satisfied: jupyter-events>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.12.0)\n",
            "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.5.3)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (7.16.6)\n",
            "Requirement already satisfied: nbformat>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (5.10.4)\n",
            "Requirement already satisfied: overrides>=5.0 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (7.7.0)\n",
            "Requirement already satisfied: prometheus-client>=0.9 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.23.1)\n",
            "Requirement already satisfied: send2trash>=1.8.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.18.1)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.12/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.5.1)\n",
            "Requirement already satisfied: babel>=2.10 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.17.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.25.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (3.1.4)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.12/dist-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.0.52)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.28.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.30.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.4)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (6.0.3)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.1.4)\n",
            "Requirement already satisfied: rfc3986-validator>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.1.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (4.13.5)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (6.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.1.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.21.2)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.12/dist-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.7.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (4.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from bleach[css]!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.4.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.8.5)\n",
            "Requirement already satisfied: fqdn in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.5.1)\n",
            "Requirement already satisfied: isoduration in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (20.11.0)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (3.0.0)\n",
            "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.1.0)\n",
            "Requirement already satisfied: uri-template in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.3.0)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (25.10.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->llms-from-scratch==1.0.18) (0.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel!=6.30.0,>=6.5.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (0.2.14)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (2.23)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.12/dist-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.3.1)\n",
            "Requirement already satisfied: arrow>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab>=4.0->llms-from-scratch==1.0.18) (1.4.0)\n",
            "Downloading jupyterlab-4.5.1-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading jupyter_lsp-2.3.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.28.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.8/59.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llms-from-scratch\n",
            "  Building wheel for llms-from-scratch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llms-from-scratch: filename=llms_from_scratch-1.0.18-py3-none-any.whl size=85993 sha256=7789ba4c9e5993ec19a45cf3d9f02b5ce2d0b20d6a216a770a1612a40467fb9e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qk7h7b2u/wheels/69/77/60/5aeaba865ec259057fd38b9ea4e7e81eaaf0c0b31fb312eb68\n",
            "Successfully built llms-from-scratch\n",
            "Installing collected packages: pip, json5, jedi, async-lru, jupyterlab-server, jupyter-lsp, jupyterlab, llms-from-scratch\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed async-lru-2.0.5 jedi-0.19.2 json5-0.12.1 jupyter-lsp-2.3.0 jupyterlab-4.5.1 jupyterlab-server-2.28.0 llms-from-scratch-1.0.18 pip-25.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ],
      "metadata": {
        "id": "kpq3eG1Pu6Tm",
        "outputId": "86b4ac5d-b816-4fe4-a53b-85e205bb4c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import (\n",
        "    generate,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ],
      "metadata": {
        "id": "mhHkHTaUu76F"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ],
      "metadata": {
        "id": "DXmJc4ZVvAZS",
        "outputId": "f598ec3f-6b11-4637-fb18-7ba954094a6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "finetuning the LLm on instruction data"
      ],
      "metadata": {
        "id": "Vk9pXBAYwDKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import (\n",
        "   calc_loss_loader,\n",
        "   train_model_simple,\n",
        " )"
      ],
      "metadata": {
        "id": "s371VLc9wG-X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "id": "W9FfIjS9wWyl",
        "outputId": "cfe7a795-6c87-4171-f3f5-50e5ba020fc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.825909376144409\n",
            "Validation loss: 3.7619347095489504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "id": "HqMt_CChwXLK",
        "outputId": "96e48b1d-7915-4ef7-cd3a-716a05123a8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.687\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.682\n",
            "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
            "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
            "Ep 2 (Step 000160): Train loss 0.412, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.667\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
            "Ep 2 (Step 000185): Train loss 0.414, Val loss 0.657\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.633\n",
            "Ep 2 (Step 000200): Train loss 0.309, Val loss 0.633\n",
            "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.631\n",
            "Ep 2 (Step 000210): Train loss 0.364, Val loss 0.630\n",
            "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.634\n",
            "Ep 2 (Step 000220): Train loss 0.297, Val loss 0.644\n",
            "Ep 2 (Step 000225): Train loss 0.342, Val loss 0.658\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.656\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "Training completed in 3.32 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llms_from_scratch.ch05 import plot_losses\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "gGzpOBeExsxG",
        "outputId": "24becb7c-86c2-4772-b39f-6760a1b07355",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extracting and saving responses"
      ],
      "metadata": {
        "id": "Pze8crr3ywDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ],
      "metadata": {
        "id": "aCwALS50ytOP",
        "outputId": "5670031a-2082-4099-a8d7-bdeadf03b0df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)"
      ],
      "metadata": {
        "id": "s8mnXduMzZgA",
        "outputId": "73a01117-83be-4539-d745-4f32b989aa8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [01:16<00:00,  1.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n"
      ],
      "metadata": {
        "id": "XNEKeSffze8n",
        "outputId": "5e9047cf-e51f-48c9-b622-80ac5a864c5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "evaluate"
      ],
      "metadata": {
        "id": "HoOarYqL0Bxm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "susTiU640QB_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}